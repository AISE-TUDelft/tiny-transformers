{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, math, numpy as np, torch\n",
    "\n",
    "from pprint import pprint\n",
    "from safetensors import safe_open\n",
    "from activations_roberta import ActivationsRobertaForMaskedLM\n",
    "from activations_gpt_neo import ActivationsGPTNeoForCausalLM\n",
    "from transformers import AutoConfig, RobertaForMaskedLM, GPTNeoForCausalLM\n",
    "\n",
    "results_dir = os.path.abspath('../../../results/upload/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_path):\n",
    "    ''' Load in model with custom activation '''\n",
    "    model_name = os.path.basename(model_path)\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    \n",
    "    if 'BERT' in model_name:\n",
    "        if 'Adaptive' in model_name or 'KAN' in model_name or 'PReLU' in model_name or 'Swish' in model_name:\n",
    "            model = ActivationsRobertaForMaskedLM(config)\n",
    "        else:\n",
    "            model = RobertaForMaskedLM(config)\n",
    "    elif 'GPT' in model_name:\n",
    "        if 'Adaptive' in model_name or 'KAN' in model_name or 'PReLU' in model_name or 'Swish' in model_name:\n",
    "            model = ActivationsGPTNeoForCausalLM(config)\n",
    "        else: \n",
    "            model = GPTNeoForCausalLM(config)\n",
    "    else:\n",
    "        raise ValueError(\"Model name must contain either 'BERT' or 'GPT'\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model_path):\n",
    "    print(model_path)\n",
    "    model_name = os.path.basename(model_path)\n",
    "    return f'Custom-Activations-{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List all model directories within the results directory\n",
    "all_model_paths = sorted([p.path for p in os.scandir(results_dir) if p.is_dir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\Filip\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, Repository, ModelCard, get_collection, add_collection_item, login\n",
    "import tqdm\n",
    "\n",
    "login('token')\n",
    "\n",
    "org_name = 'AISE-TUDelft' \n",
    "collection_name = 'brp-tiny-transformers-666c352b3b570f44d7d2a519'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\BERT-Adaptive-GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 39.5M/39.5M [00:04<00:00, 8.26MB/s]\n",
      "  8%|▊         | 1/13 [00:06<01:20,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-BERT-Adaptive-GELU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\BERT-GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 39.5M/39.5M [00:04<00:00, 8.07MB/s]\n",
      " 15%|█▌        | 2/13 [00:13<01:12,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-BERT-GELU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\BERT-PReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 39.5M/39.5M [00:04<00:00, 8.37MB/s]\n",
      " 23%|██▎       | 3/13 [00:19<01:05,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-BERT-PReLU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\BERT-ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 39.5M/39.5M [00:04<00:00, 9.31MB/s]\n",
      " 31%|███       | 4/13 [00:25<00:57,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-BERT-ReLU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\BERT-SiLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 39.5M/39.5M [00:04<00:00, 9.21MB/s]\n",
      " 38%|███▊      | 5/13 [00:31<00:50,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-BERT-SiLU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\BERT-Swish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 39.5M/39.5M [00:04<00:00, 8.63MB/s]\n",
      " 46%|████▌     | 6/13 [00:38<00:43,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-BERT-Swish\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-Adaptive-GELU\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 38.9M/38.9M [00:04<00:00, 9.53MB/s]\n",
      " 54%|█████▍    | 7/13 [00:44<00:36,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-Adaptive-GELU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 38.9M/38.9M [00:04<00:00, 9.16MB/s]\n",
      " 62%|██████▏   | 8/13 [00:49<00:30,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-GELU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-KAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 47.3M/47.3M [00:04<00:00, 10.0MB/s]\n",
      " 69%|██████▉   | 9/13 [00:56<00:25,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-KAN\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-PReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 38.9M/38.9M [00:04<00:00, 9.34MB/s]\n",
      " 77%|███████▋  | 10/13 [01:02<00:18,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-PReLU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 38.9M/38.9M [00:05<00:00, 7.38MB/s]\n",
      " 85%|████████▍ | 11/13 [01:09<00:12,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-ReLU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-SiLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 38.9M/38.9M [00:04<00:00, 9.46MB/s]\n",
      " 92%|█████████▏| 12/13 [01:15<00:06,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-SiLU\n",
      "c:\\Users\\Filip\\Documents\\School\\Delft\\Research project\\results\\upload\\GPT-Swish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 38.9M/38.9M [00:04<00:00, 9.62MB/s]\n",
      "100%|██████████| 13/13 [01:21<00:00,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded Custom-Activations-GPT-Swish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_path in tqdm.tqdm(all_model_paths):\n",
    "    \n",
    "    model_name = get_model_name(model_path)\n",
    "    hf_model = get_model(model_path)\n",
    "\n",
    "    hf_path = f'{org_name}/{model_name}'\n",
    "    hf_model.push_to_hub(repo_id=hf_path)\n",
    "\n",
    "    print(f'uploaded {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

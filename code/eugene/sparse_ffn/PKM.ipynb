{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72a660b-85df-4474-abac-8c9c00dd11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d24138d-4b13-401c-9a3e-dcebcee7d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryNetwork(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, num_heads, batch_norm = True):\n",
    "        super(QueryNetwork, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.batch_norm = batch_norm\n",
    "        self.Wq = nn.Linear(dim_in, dim_hidden * num_heads, bias = False)\n",
    "        self.bn = nn.BatchNorm1d(dim_hidden * num_heads)\n",
    "    def forward(self, x):\n",
    "        # for memory of size less than 384*384 the paper says that batch norm gives no significant improvement\n",
    "        # when using batch norm, padding tokens in the sequence can skew mean and variance estimate\n",
    "        query = self.Wq(x)\n",
    "        \n",
    "        if self.batch_norm:\n",
    "            original_shape = query.shape\n",
    "            query = query.reshape(-1, self.dim_hidden * self.num_heads)\n",
    "            normalized = self.bn(query)\n",
    "            normalized = normalized.reshape(original_shape)\n",
    "            return normalized.reshape(*normalized.shape[:-1], self.num_heads, self.dim_hidden)\n",
    "        else:\n",
    "            return query.reshape(*query.shape[:-1], self.num_heads, self.dim_hidden) # batch size x context length x num heads x query dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f6c7dd-108b-4e97-82ca-40e24d05d09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 4, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn = QueryNetwork(7,5, 4)\n",
    "qn(torch.rand(100,10,7)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "918b4c9f-9c95-494f-8264-650fcbf36aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductKey(nn.Module):\n",
    "    def __init__(self, dim, num_subkeys, top_k, num_heads):\n",
    "        super(ProductKey, self).__init__()\n",
    "        assert dim % 2 == 0, \"key must be able to be split into 2\"\n",
    "        self.dim = dim\n",
    "        self.subkey_size = dim // 2\n",
    "        self.top_k = top_k\n",
    "        self.num_subkeys = num_subkeys\n",
    "        \n",
    "        keyl = torch.empty(num_heads, num_subkeys, self.subkey_size)\n",
    "        keyr = torch.empty(num_heads, num_subkeys, self.subkey_size)\n",
    "\n",
    "        std = 1/math.sqrt(dim)\n",
    "        keyl.uniform_(-std, std)\n",
    "        keyr.uniform_(-std, std)\n",
    "\n",
    "        self.keyl = nn.Parameter(keyl)\n",
    "        self.keyr = nn.Parameter(keyr)\n",
    "\n",
    "    def forward(self, query):\n",
    "        # multihead query\n",
    "        batch, context_length, num_heads, query_size = query.shape\n",
    "        \n",
    "        queryl = query[..., :self.subkey_size]\n",
    "        queryr = query[..., self.subkey_size:]\n",
    "\n",
    "        scorel = torch.einsum('bcnq,nkq->bcnk', queryl, self.keyl) # batch size x context length x num head x subquery length , num heads x num keys x subquery length\n",
    "        scorer = torch.einsum('bcnq,nkq->bcnk', queryr, self.keyr)\n",
    "\n",
    "        top_keys_l, top_idx_l = scorel.topk(self.top_k) # batch, context, heads, top k\n",
    "        top_keys_r, top_idx_r = scorer.topk(self.top_k)\n",
    "\n",
    "        #duplicate along the rows\n",
    "        product_scores_l = top_keys_l.reshape(*top_keys_l.shape[:-1], top_keys_l.shape[-1], 1).expand(*top_keys_l.shape[:-1], top_keys_l.shape[-1], top_keys_l.shape[-1])\n",
    "        # duplicate along the columns\n",
    "        product_scores_r = top_keys_r.reshape(*top_keys_r.shape[:-1], 1, top_keys_r.shape[-1]).expand(*top_keys_r.shape[:-1], top_keys_r.shape[-1], top_keys_r.shape[-1])\n",
    "\n",
    "        product_scores = (product_scores_l + product_scores_r) # batch, context, heads, top k, top k\n",
    "        product_scores = product_scores.reshape(batch, context_length, num_heads, self.top_k * self.top_k)\n",
    "\n",
    "        product_indices_l = top_idx_l.reshape(*top_idx_l.shape[:-1], top_idx_l.shape[-1], 1).expand(*top_idx_l.shape[:-1], top_idx_l.shape[-1], top_idx_l.shape[-1])\n",
    "        product_indices_r = top_idx_r.reshape(*top_idx_r.shape[:-1], top_idx_r.shape[-1], 1).expand(*top_idx_r.shape[:-1], top_idx_r.shape[-1], top_idx_r.shape[-1]) \n",
    "\n",
    "        product_indices = product_indices_l * self.num_subkeys + product_indices_r\n",
    "        product_indices = product_indices.reshape(batch, context_length, num_heads, self.top_k * self.top_k)\n",
    "\n",
    "        top_product_scores, top_product_indices = product_scores.topk(self.top_k)\n",
    "        selected_value_weights = F.softmax(top_product_scores, dim=-1)\n",
    "        selected_value_indices = torch.gather(product_indices, -1, top_product_indices)\n",
    "        #print(top_product_scores)\n",
    "        #print(torch.gather(product_scores, -1, top_product_indices)) # they should be equal\n",
    "        return selected_value_weights, selected_value_indices\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b9e3721-6d17-48df-b629-a084adebbb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2253, 0.5491, 0.1194, 0.7783],\n",
      "          [0.2550, 0.9119, 0.3249, 0.9291],\n",
      "          [0.4815, 0.4903, 0.6554, 0.1917]],\n",
      "\n",
      "         [[0.5868, 0.9642, 0.2588, 0.4964],\n",
      "          [0.3499, 0.1581, 0.0349, 0.5953],\n",
      "          [0.7301, 0.7644, 0.8572, 0.3248]]]])\n",
      "tensor([[[[0.2253, 0.5491],\n",
      "          [0.2550, 0.9119],\n",
      "          [0.4815, 0.4903]],\n",
      "\n",
      "         [[0.5868, 0.9642],\n",
      "          [0.3499, 0.1581],\n",
      "          [0.7301, 0.7644]]]])\n",
      "tensor([[[[0.1194, 0.7783],\n",
      "          [0.3249, 0.9291],\n",
      "          [0.6554, 0.1917]],\n",
      "\n",
      "         [[0.2588, 0.4964],\n",
      "          [0.0349, 0.5953],\n",
      "          [0.8572, 0.3248]]]])\n"
     ]
    }
   ],
   "source": [
    "block = torch.rand(1,2,3,4)\n",
    "print(block)\n",
    "print(block[...,:2])\n",
    "print(block[...,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9de3f4-8fc3-429d-b465-cd5e05b21be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3561],\n",
      "         [0.9040],\n",
      "         [0.2236],\n",
      "         [0.9060]],\n",
      "\n",
      "        [[0.8523],\n",
      "         [0.1579],\n",
      "         [0.4793],\n",
      "         [0.3675]]])\n",
      "tensor([[[0.3561, 0.3561, 0.3561, 0.3561],\n",
      "         [0.9040, 0.9040, 0.9040, 0.9040],\n",
      "         [0.2236, 0.2236, 0.2236, 0.2236],\n",
      "         [0.9060, 0.9060, 0.9060, 0.9060]],\n",
      "\n",
      "        [[0.8523, 0.8523, 0.8523, 0.8523],\n",
      "         [0.1579, 0.1579, 0.1579, 0.1579],\n",
      "         [0.4793, 0.4793, 0.4793, 0.4793],\n",
      "         [0.3675, 0.3675, 0.3675, 0.3675]]])\n",
      "tensor([[[0.3561, 0.9040, 0.2236, 0.9060],\n",
      "         [0.3561, 0.9040, 0.2236, 0.9060],\n",
      "         [0.3561, 0.9040, 0.2236, 0.9060],\n",
      "         [0.3561, 0.9040, 0.2236, 0.9060]],\n",
      "\n",
      "        [[0.8523, 0.1579, 0.4793, 0.3675],\n",
      "         [0.8523, 0.1579, 0.4793, 0.3675],\n",
      "         [0.8523, 0.1579, 0.4793, 0.3675],\n",
      "         [0.8523, 0.1579, 0.4793, 0.3675]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,4,1)\n",
    "print(a)\n",
    "print(a.expand(2,4,4))\n",
    "b = a.reshape(2,1,4)\n",
    "print(b.expand(2,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "399c87ad-2203-457b-bd89-a73fe2d0a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9406,  0.8643],\n",
      "          [ 0.1486,  0.1485],\n",
      "          [ 1.3653,  1.2828],\n",
      "          [ 0.5725,  0.5647]],\n",
      "\n",
      "         [[ 1.1675,  0.9089],\n",
      "          [ 0.0824, -0.0272],\n",
      "          [ 0.3099,  0.1507],\n",
      "          [ 0.2130,  0.1989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4970,  0.3907],\n",
      "          [ 0.3884,  0.3348],\n",
      "          [-0.1141, -0.1393],\n",
      "          [ 0.4365,  0.1453]],\n",
      "\n",
      "         [[ 0.3047,  0.1988],\n",
      "          [ 0.7850,  0.7605],\n",
      "          [ 0.9413,  0.8459],\n",
      "          [ 0.4884,  0.4194]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8606,  0.8399],\n",
      "          [ 0.3752,  0.2896],\n",
      "          [ 2.5514,  2.4396],\n",
      "          [ 0.2540,  0.1578]],\n",
      "\n",
      "         [[ 1.0256,  0.6873],\n",
      "          [ 1.2209,  0.9314],\n",
      "          [ 1.2635,  1.1965],\n",
      "          [ 0.4429,  0.2562]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4367,  0.3870],\n",
      "          [ 0.8675,  0.8348],\n",
      "          [ 1.7378,  1.5173],\n",
      "          [ 0.5041,  0.4577]],\n",
      "\n",
      "         [[ 0.6319,  0.4495],\n",
      "          [ 0.1568,  0.1509],\n",
      "          [-0.0641, -0.1277],\n",
      "          [ 0.6859,  0.2412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0164, -0.0405],\n",
      "          [ 0.8806,  0.8216],\n",
      "          [-0.0587, -0.1150],\n",
      "          [ 1.8261,  1.7571]],\n",
      "\n",
      "         [[ 0.1275,  0.1055],\n",
      "          [ 0.4726,  0.3700],\n",
      "          [ 1.3724,  1.2634],\n",
      "          [ 0.5831,  0.3277]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0775,  0.0742],\n",
      "          [ 0.4330,  0.1387],\n",
      "          [ 1.0325,  0.4593],\n",
      "          [ 0.2037,  0.0958]],\n",
      "\n",
      "         [[ 0.7193,  0.5532],\n",
      "          [ 0.8008,  0.6440],\n",
      "          [ 0.7569,  0.5654],\n",
      "          [ 1.1721,  0.4731]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3222,  0.3129],\n",
      "          [ 0.7712,  0.7683],\n",
      "          [ 1.0508,  0.6690],\n",
      "          [ 2.1417,  1.9135]],\n",
      "\n",
      "         [[ 0.3902,  0.3054],\n",
      "          [ 0.6536,  0.2317],\n",
      "          [-0.0841, -0.1019],\n",
      "          [ 0.9331,  0.9164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3997,  0.3379],\n",
      "          [ 0.5021,  0.4168],\n",
      "          [ 0.4497,  0.2751],\n",
      "          [ 1.2964,  0.7696]],\n",
      "\n",
      "         [[ 0.5598,  0.4394],\n",
      "          [ 0.7844,  0.4744],\n",
      "          [ 1.1219,  1.0976],\n",
      "          [ 0.7728,  0.3859]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2202,  0.1660],\n",
      "          [ 0.6925,  0.5704],\n",
      "          [-0.4943, -0.5171],\n",
      "          [ 1.6029,  0.8219]],\n",
      "\n",
      "         [[ 0.3507,  0.3332],\n",
      "          [ 0.0497,  0.0462],\n",
      "          [ 0.1036, -0.1940],\n",
      "          [ 1.4342,  0.8902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1380,  0.0289],\n",
      "          [ 0.6342,  0.4993],\n",
      "          [ 1.0190,  0.9491],\n",
      "          [ 0.8144,  0.6635]],\n",
      "\n",
      "         [[ 0.1453,  0.1103],\n",
      "          [ 0.2906,  0.1713],\n",
      "          [-0.0465, -0.3792],\n",
      "          [ 0.7924,  0.7072]]]], grad_fn=<TopkBackward0>)\n",
      "tensor([[[[ 0.9406,  0.8643],\n",
      "          [ 0.1486,  0.1485],\n",
      "          [ 1.3653,  1.2828],\n",
      "          [ 0.5725,  0.5647]],\n",
      "\n",
      "         [[ 1.1675,  0.9089],\n",
      "          [ 0.0824, -0.0272],\n",
      "          [ 0.3099,  0.1507],\n",
      "          [ 0.2130,  0.1989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4970,  0.3907],\n",
      "          [ 0.3884,  0.3348],\n",
      "          [-0.1141, -0.1393],\n",
      "          [ 0.4365,  0.1453]],\n",
      "\n",
      "         [[ 0.3047,  0.1988],\n",
      "          [ 0.7850,  0.7605],\n",
      "          [ 0.9413,  0.8459],\n",
      "          [ 0.4884,  0.4194]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8606,  0.8399],\n",
      "          [ 0.3752,  0.2896],\n",
      "          [ 2.5514,  2.4396],\n",
      "          [ 0.2540,  0.1578]],\n",
      "\n",
      "         [[ 1.0256,  0.6873],\n",
      "          [ 1.2209,  0.9314],\n",
      "          [ 1.2635,  1.1965],\n",
      "          [ 0.4429,  0.2562]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4367,  0.3870],\n",
      "          [ 0.8675,  0.8348],\n",
      "          [ 1.7378,  1.5173],\n",
      "          [ 0.5041,  0.4577]],\n",
      "\n",
      "         [[ 0.6319,  0.4495],\n",
      "          [ 0.1568,  0.1509],\n",
      "          [-0.0641, -0.1277],\n",
      "          [ 0.6859,  0.2412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0164, -0.0405],\n",
      "          [ 0.8806,  0.8216],\n",
      "          [-0.0587, -0.1150],\n",
      "          [ 1.8261,  1.7571]],\n",
      "\n",
      "         [[ 0.1275,  0.1055],\n",
      "          [ 0.4726,  0.3700],\n",
      "          [ 1.3724,  1.2634],\n",
      "          [ 0.5831,  0.3277]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0775,  0.0742],\n",
      "          [ 0.4330,  0.1387],\n",
      "          [ 1.0325,  0.4593],\n",
      "          [ 0.2037,  0.0958]],\n",
      "\n",
      "         [[ 0.7193,  0.5532],\n",
      "          [ 0.8008,  0.6440],\n",
      "          [ 0.7569,  0.5654],\n",
      "          [ 1.1721,  0.4731]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3222,  0.3129],\n",
      "          [ 0.7712,  0.7683],\n",
      "          [ 1.0508,  0.6690],\n",
      "          [ 2.1417,  1.9135]],\n",
      "\n",
      "         [[ 0.3902,  0.3054],\n",
      "          [ 0.6536,  0.2317],\n",
      "          [-0.0841, -0.1019],\n",
      "          [ 0.9331,  0.9164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3997,  0.3379],\n",
      "          [ 0.5021,  0.4168],\n",
      "          [ 0.4497,  0.2751],\n",
      "          [ 1.2964,  0.7696]],\n",
      "\n",
      "         [[ 0.5598,  0.4394],\n",
      "          [ 0.7844,  0.4744],\n",
      "          [ 1.1219,  1.0976],\n",
      "          [ 0.7728,  0.3859]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2202,  0.1660],\n",
      "          [ 0.6925,  0.5704],\n",
      "          [-0.4943, -0.5171],\n",
      "          [ 1.6029,  0.8219]],\n",
      "\n",
      "         [[ 0.3507,  0.3332],\n",
      "          [ 0.0497,  0.0462],\n",
      "          [ 0.1036, -0.1940],\n",
      "          [ 1.4342,  0.8902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1380,  0.0289],\n",
      "          [ 0.6342,  0.4993],\n",
      "          [ 1.0190,  0.9491],\n",
      "          [ 0.8144,  0.6635]],\n",
      "\n",
      "         [[ 0.1453,  0.1103],\n",
      "          [ 0.2906,  0.1713],\n",
      "          [-0.0465, -0.3792],\n",
      "          [ 0.7924,  0.7072]]]], grad_fn=<GatherBackward0>)\n"
     ]
    }
   ],
   "source": [
    "qn = QueryNetwork(7,6, 4)\n",
    "query = qn(torch.rand(10,2,7))\n",
    "#print(query.shape)\n",
    "key = ProductKey(6, 3, 2, 4)\n",
    "key(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0fdba940-bcfa-4049-b800-6556ad16cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKM(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, num_subkeys, top_k, num_heads, batch_norm = True):\n",
    "        super(PKM, self).__init__()\n",
    "        self.dim_in, self.dim_hidden, self.num_subkeys, self.top_k, self.num_heads = dim_in, dim_hidden, num_subkeys, top_k, num_heads\n",
    "        self.query_network = QueryNetwork(dim_in, dim_hidden, num_heads, batch_norm)\n",
    "        self.key_table = ProductKey(dim_hidden, num_subkeys, top_k, num_heads)\n",
    "        self.value_table = nn.Embedding(num_subkeys * num_subkeys, dim_in)\n",
    "    def forward(self, x):\n",
    "        queries = self.query_network(x)\n",
    "        weights, indices = self.key_table(queries) # shape is batch, context length, num heads, top k\n",
    "        original_shape = weights.shape\n",
    "        \n",
    "        weights, indices = weights.reshape(-1, self.top_k), indices.reshape(-1, self.top_k)\n",
    "        values = self.value_table(indices)\n",
    "        weights = weights.reshape(original_shape)\n",
    "        values = values.reshape(*original_shape, self.dim_in)\n",
    "\n",
    "        weighted_values = torch.einsum('bcnk,bcnkd->bcd', weights, values) # take linear combination of weights & values and sum over all heads\n",
    "\n",
    "        return weighted_values\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7dd73f-e43d-435d-8c52-9ac289d659d8",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54917707-48bc-4dce-aa1a-0c7f73745f59",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89105a3e-fed6-4186-a745-b028d0ddc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_network = QueryNetwork(6,4,2,False)\n",
    "dumb_query_network = [nn.Linear(10, 5, bias=False), nn.Linear(10, 5, bias=False)]\n",
    "dumb_query_network[0].weight.data = query_network.Wq.weight.data[:4,...]\n",
    "dumb_query_network[1].weight.data = query_network.Wq.weight.data[4:,...]\n",
    "data = torch.rand(1,1,6)\n",
    "query_out = query_network(data)\n",
    "head_0_out = dumb_query_network[0](data)\n",
    "head_1_out = dumb_query_network[1](data)\n",
    "\n",
    "assert torch.equal(query_out[...,0,:], head_0_out)\n",
    "assert torch.equal(query_out[...,1,:], head_1_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5584525-ab03-4e4d-b598-a58776992c46",
   "metadata": {},
   "source": [
    "## Product key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d96ea72f-6431-456b-aaaf-14b7ba99883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumbProductKey(nn.Module):\n",
    "    def __init__(self, dim, num_subkeys, top_k):\n",
    "        super(DumbProductKey, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.subkey_size = dim // 2\n",
    "        self.num_subkeys = num_subkeys\n",
    "        self.top_k = top_k\n",
    "        self.keyl = nn.Linear(self.subkey_size, num_subkeys, bias = False)\n",
    "        self.keyr = nn.Linear(self.subkey_size, num_subkeys, bias = False)\n",
    "    def forward(self, x):\n",
    "        batch_size, context_length, query_size = x.shape\n",
    "        query_l = x[..., :self.subkey_size]\n",
    "        query_r = x[..., self.subkey_size:]\n",
    "        top_left_keys, top_left_indices = self.keyl(query_l).topk(self.top_k)\n",
    "        top_right_keys, top_right_indices = self.keyr(query_r).topk(self.top_k)\n",
    "        product_keys_left = top_left_keys.reshape(batch_size, context_length, self.top_k, 1).expand(batch_size, context_length, self.top_k, self.top_k)\n",
    "        product_keys_right = top_right_keys.reshape(batch_size, context_length, 1, self.top_k).expand(batch_size, context_length, self.top_k, self.top_k)\n",
    "        product_keys = product_keys_left + product_keys_right\n",
    "        product_indices_left = top_left_indices.reshape(batch_size, context_length, self.top_k, 1).expand(batch_size, context_length, self.top_k, self.top_k)\n",
    "        product_keys_right = top_right_indices.reshape(batch_size, context_length, self.top_k, 1).expand(batch_size, context_length, self.top_k, self.top_k)\n",
    "        product_indices = product_indices_left * self.num_subkeys + product_keys_right\n",
    "        product_keys = product_keys.reshape(batch_size, context_length, self.top_k * self.top_k)\n",
    "        product_indices = product_indices.reshape(batch_size, context_length, self.top_k * self.top_k)\n",
    "        top_keys, top_indices = product_keys.topk(self.top_k)\n",
    "        top_indices = torch.gather(product_indices, -1, top_indices)\n",
    "        top_weights = F.softmax(top_keys, dim=-1)\n",
    "        return top_weights, top_indices\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4279d4b1-7477-45b7-be2d-cea95ce30b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "dpk0 = DumbProductKey(10, 3, 2)\n",
    "dpk1 = DumbProductKey(10, 3, 2)\n",
    "pk = ProductKey(10, 3, top_k=2, num_heads=2)\n",
    "print(pk.keyl.data[0].shape)\n",
    "pk.keyl.data[0], pk.keyl.data[1]  = dpk0.keyl.weight.data, dpk1.keyl.weight.data\n",
    "pk.keyr.data[0], pk.keyr.data[1] = dpk0.keyr.weight.data, dpk1.keyr.weight.data\n",
    "data = torch.rand(1,1,2,10)\n",
    "pk_out = pk(data)\n",
    "dpk0_out = dpk0(data[:,:,0,:])\n",
    "dpk1_out = dpk1(data[:,:,1,:])\n",
    "\n",
    "assert torch.equal(pk_out[0][:,:,0,:], dpk0_out[0])\n",
    "assert torch.equal(pk_out[0][:,:,1,:], dpk1_out[0])\n",
    "assert torch.equal(pk_out[1][:,:,0,:], dpk0_out[1])\n",
    "assert torch.equal(pk_out[1][:,:,1,:], dpk1_out[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7000a-0bbc-4202-abd6-3bf528a1b25d",
   "metadata": {},
   "source": [
    "## PKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f6f38c08-bc82-47bd-98fc-7c39a50bb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumbPKM(nn.Module): \n",
    "    # inefficient implementation to verify correctness\n",
    "    def __init__(self, dim_in, dim_hidden, num_subkeys, top_k, num_heads, batch_norm = True):\n",
    "        super(DumbPKM, self).__init__()\n",
    "        self.dim_in, self.dim_hidden, self.num_subkeys, self.top_k, self.num_heads = dim_in, dim_hidden, num_subkeys, top_k, num_heads\n",
    "        self.query_network = QueryNetwork(dim_in, dim_hidden, num_heads, batch_norm)\n",
    "        self.key_table = ProductKey(dim_hidden, num_subkeys, top_k, num_heads)\n",
    "        self.value_table = nn.Embedding(num_subkeys * num_subkeys, dim_in)\n",
    "    def forward(self, x):\n",
    "        queries = self.query_network(x)\n",
    "        weights, indices = self.key_table(queries) # shape is batch, context length, num heads, top k\n",
    "        \n",
    "        #weights, indices = weights.reshape(-1, self.top_k), indices.reshape(-1, self.top_k)\n",
    "        values = self.value_table(indices)\n",
    "        #weights = weights.reshape(original_shape)\n",
    "        #values = values.reshape(*original_shape, self.dim_in)\n",
    "        # print(weights)\n",
    "        # print(values)\n",
    "        # print((weights.unsqueeze(-1) * values).shape )\n",
    "        weighted_values = (weights.unsqueeze(-1) * values).sum(dim=2).sum(dim=2)# take linear combination of weights & values and sum over all heads\n",
    "        \n",
    "        return weighted_values\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d74d6d5d-ad83-4336-8bf5-7182090ab1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3421, 0.3416, 0.3163],\n",
      "          [0.3505, 0.3462, 0.3033]]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[[-0.2813, -1.3299, -0.6538,  1.7198, -0.9610, -0.6375, -0.8870,\n",
      "             0.8388,  1.1529, -1.7611],\n",
      "           [-0.2813, -1.3299, -0.6538,  1.7198, -0.9610, -0.6375, -0.8870,\n",
      "             0.8388,  1.1529, -1.7611],\n",
      "           [-0.2813, -1.3299, -0.6538,  1.7198, -0.9610, -0.6375, -0.8870,\n",
      "             0.8388,  1.1529, -1.7611]],\n",
      "\n",
      "          [[-0.9069, -0.5918,  0.1508, -1.0411, -1.1559, -0.3167,  0.9403,\n",
      "            -1.1470,  0.7928,  0.0832],\n",
      "           [-0.9069, -0.5918,  0.1508, -1.0411, -1.1559, -0.3167,  0.9403,\n",
      "            -1.1470,  0.7928,  0.0832],\n",
      "           [-1.1070, -1.7174,  1.5346, -0.0032,  1.4403, -0.1106,  0.5769,\n",
      "            -0.1692,  1.1887, -0.1575]]]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 1, 2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "dpkm = DumbPKM(10,6,5,3,2, False)\n",
    "torch.manual_seed(0)\n",
    "pkm = PKM(10,6,5,3,2, False)\n",
    "data = torch.rand(1,1,10)\n",
    "dpkm_out = dpkm(data)\n",
    "pkm_out = pkm(data)\n",
    "assert torch.allclose(dpkm_out, pkm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e373542-8e5d-49e1-a97f-87ac31210750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

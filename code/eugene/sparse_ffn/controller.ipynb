{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35280225-3a17-4ed5-9c34-40eea0f6fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59d8d44-ce7f-4d6d-8af2-0b10ae3999c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    def __init__(self, dim_in, dim_lowrank, dim_hidden, num_blocks):\n",
    "        super(Controller, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_lowrank = dim_lowrank\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_blocks = num_blocks\n",
    "        assert self.dim_hidden % self.num_blocks == 0, \"hidden vector must be divisible into N blocks\"\n",
    "        self.U = nn.Linear(dim_in, dim_lowrank, bias = False)\n",
    "        self.V = nn.Linear(dim_lowrank, dim_hidden, bias = False)\n",
    "    def forward(self, x):\n",
    "        logits = self.V(self.U(x))\n",
    "        original_shape = logits.shape\n",
    "        logits = logits.reshape(*logits.shape[:-1], self.num_blocks, self.dim_hidden // self.num_blocks)\n",
    "        if self.training:\n",
    "            mask = F.gumbel_softmax(logits, tau=0.1, hard=True)\n",
    "            return mask.reshape(original_shape)\n",
    "        else:\n",
    "            selected = torch.argmax(logits, dim=-1)\n",
    "            mask = F.one_hot(selected, num_classes = self.dim_hidden // self.num_blocks)\n",
    "            return mask.reshape(original_shape)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298823f7-33a8-42f4-921e-cc472b4dfb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8200, 0.7036, 0.2224, 0.4481],\n",
      "          [0.6884, 0.9172, 0.6434, 0.4819],\n",
      "          [0.2516, 0.6864, 0.6995, 0.4641]],\n",
      "\n",
      "         [[0.7833, 0.0350, 0.8097, 0.2948],\n",
      "          [0.4111, 0.9093, 0.7296, 0.9314],\n",
      "          [0.8385, 0.9954, 0.9574, 0.2396]],\n",
      "\n",
      "         [[0.5223, 0.8909, 0.0233, 0.5707],\n",
      "          [0.0803, 0.1416, 0.1115, 0.6671],\n",
      "          [0.7048, 0.2429, 0.8210, 0.7969]],\n",
      "\n",
      "         [[0.2291, 0.8161, 0.5855, 0.9163],\n",
      "          [0.9725, 0.7026, 0.8404, 0.8103],\n",
      "          [0.2154, 0.5107, 0.9583, 0.8376]],\n",
      "\n",
      "         [[0.4464, 0.6062, 0.3336, 0.8799],\n",
      "          [0.1320, 0.7307, 0.0491, 0.3558],\n",
      "          [0.3795, 0.6653, 0.8301, 0.7284]]],\n",
      "\n",
      "\n",
      "        [[[0.2127, 0.1470, 0.8098, 0.9140],\n",
      "          [0.9478, 0.1481, 0.3205, 0.0146],\n",
      "          [0.0550, 0.4292, 0.6248, 0.4054]],\n",
      "\n",
      "         [[0.4921, 0.7932, 0.3811, 0.2717],\n",
      "          [0.6979, 0.5866, 0.2212, 0.5477],\n",
      "          [0.6557, 0.9372, 0.2888, 0.7619]],\n",
      "\n",
      "         [[0.0366, 0.5994, 0.2568, 0.7806],\n",
      "          [0.2840, 0.6073, 0.8163, 0.1236],\n",
      "          [0.8751, 0.0531, 0.5537, 0.6229]],\n",
      "\n",
      "         [[0.0696, 0.5657, 0.6065, 0.7226],\n",
      "          [0.0992, 0.1684, 0.3485, 0.0756],\n",
      "          [0.5325, 0.6088, 0.8816, 0.2119]],\n",
      "\n",
      "         [[0.5900, 0.6520, 0.3439, 0.0416],\n",
      "          [0.0765, 0.4642, 0.9470, 0.4133],\n",
      "          [0.1540, 0.7149, 0.2529, 0.1756]]]])\n",
      "tensor([[[[1, 0, 0, 0],\n",
      "          [0, 1, 0, 0],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 0, 1, 0],\n",
      "          [0, 0, 0, 1],\n",
      "          [0, 1, 0, 0]],\n",
      "\n",
      "         [[0, 1, 0, 0],\n",
      "          [0, 0, 0, 1],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [1, 0, 0, 0],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [0, 1, 0, 0],\n",
      "          [0, 0, 1, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 1],\n",
      "          [1, 0, 0, 0],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 1, 0, 0],\n",
      "          [1, 0, 0, 0],\n",
      "          [0, 1, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [0, 0, 1, 0],\n",
      "          [1, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [0, 0, 1, 0],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 1, 0, 0],\n",
      "          [0, 0, 1, 0],\n",
      "          [0, 1, 0, 0]]]])\n",
      "tensor([[[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand(2,5,3,4)\n",
    "am = torch.argmax(A,dim=-1)\n",
    "onehot = F.one_hot(am, num_classes=4)\n",
    "print(A)\n",
    "print(onehot)\n",
    "print(onehot.reshape(2,5,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdef3c49-439b-4eef-9459-81ae2773b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.],\n",
      "          [0., 0., 0., 1.],\n",
      "          [0., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.],\n",
      "          [0., 0., 0., 1.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 1.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 1., 0., 0.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [0., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.]]]])\n",
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand(2,5,3,4)\n",
    "gs = F.gumbel_softmax(A, tau=0.1, hard=True)\n",
    "print(gs)\n",
    "print(gs.reshape(2,5,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb9eb1b-6178-4465-bc66-6d49a654e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 50, 8])\n"
     ]
    }
   ],
   "source": [
    "cnt = Controller(6,3,8,2)\n",
    "print(cnt(torch.rand(100,50,6)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2115129a-c942-433b-b19e-bcc375c2b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControllerFFN(nn.Module):\n",
    "    def __init__(self, dim_in, dim_lowrank, dim_hidden, num_blocks):\n",
    "        super(ControllerFFN, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_lowrank = dim_lowrank\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_blocks = num_blocks\n",
    "        assert self.dim_hidden % self.num_blocks == 0, \"hidden vector must be divisible into N blocks\"\n",
    "        self.controller = Controller(dim_in, dim_lowrank, dim_hidden, num_blocks)\n",
    "        self.layer1 = nn.Linear(dim_in, dim_hidden)\n",
    "        self.layer2 = nn.Linear(dim_hidden, dim_in)\n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.controller(x)* F.relu(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aae9020-9cb0-4f81-854f-c4ca6b2b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 50, 6])\n"
     ]
    }
   ],
   "source": [
    "cntffn = ControllerFFN(6,3,8,2)\n",
    "print(cntffn(torch.rand(100,50,6)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d6e90-31c6-4ab9-a71b-82303563fd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70743480-7490-426c-bb73-0424dd0192c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ee9915-f74e-4a24-9b0d-ce47dbb9e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparse_gpt_neo import SparseGPTNeoForCausalLM\n",
    "from sparse_roberta import SparseRobertaForMaskedLM\n",
    "from pretrain import load_tokenizer_and_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b259af2-b705-4ea3-9b3e-c7764db089c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = [\"gpt\", \"roberta\"]\n",
    "sparsity_type = [\"moe\", \"cnt\", \"pkm\"]\n",
    "sparsity_level = [\"high\", \"medium\", \"low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63bc714a-07e5-4132-a0ef-07f48298af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt baseline  7421440\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta baseline  7500048\n"
     ]
    }
   ],
   "source": [
    "for mt in model_type:\n",
    "    st = \"baseline\"\n",
    "    sl = \"\"    \n",
    "    name = f\"{mt} {st} {sl}\"\n",
    "    _, model = load_tokenizer_and_model(mt, st, sl)\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528bc86a-cef6-4c36-97a0-33e50f84ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt moe high 7422968\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt moe medium 7422968\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt moe low 7422968\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt cnt high 7425280\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt cnt medium 7424384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt cnt low 7390080\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt pkm high 7396352\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt pkm medium 7396352\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "gpt pkm low 7396352\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta moe high 7501576\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta moe medium 7501576\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta moe low 7501576\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta cnt high 7503888\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta cnt medium 7502992\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta cnt low 7468688\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta pkm high 7474960\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta pkm medium 7474960\n",
      "padding token is <pad>\n",
      "padding token in config: 0, in tokeniser: 0\n",
      "roberta pkm low 7474960\n"
     ]
    }
   ],
   "source": [
    "for mt in model_type:\n",
    "    for st in sparsity_type:\n",
    "        for sl in sparsity_level:\n",
    "            name = f\"{mt} {st} {sl}\"\n",
    "            _, model = load_tokenizer_and_model(mt, st, sl)\n",
    "            model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "            params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "            print(name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85a133-0320-407e-bce0-c55e1409c71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
